# Spotify ETL 
At the core of this project is the process of extracting data from spotify on user listening history, doing some basic transformation on the data and loading the data to a warehouse for user song play analytics. The program we are building uses [Spotipy](https://spotipy.readthedocs.io/en/2.16.1/) which is a lightweight Python library for the [Spotify Web API](https://developer.spotify.com/documentation/web-api/). We are interested in collecting user listening history for each user participating in this project, transform the data using python to clean it up, create unique identifiers and load the it to a Postgres database. The loading piece is done on the local machine of each user. After the data is loaded to a database, we use SQL to query the data and Python schedule an automated weekly email giving a summary of the spotify user song plays for the week. Metrics are built in the email utilizing SQL. The metrics are similar those seen in [Spotify Wrapped](https://en.wikipedia.org/wiki/Spotify_Wrapped).

# Extracting: Spotify API
Data is extracted from Spotify using this [endpoint](https://developer.spotify.com/documentation/web-api/reference/#/operations/get-recently-played) to get the 50 most recent played tracks. The result of calling is endpoint is a python [dictionary](https://docs.python.org/3/tutorial/datastructures.html#dictionaries) data structure which is then used to create multiple [dataframe](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) (A 2 dimensional data structure) after some clean up. 

# Transformation: Python and Pandas
Python and Pandas work hand-in-glove to transform the data that was extracted. [Pandas](https://docs.python.org/3/tutorial/datastructures.html#dictionaries) is a python library that is widely used for data science work because of it's data manipulation capabilities. The transformations here include removing duplicate albums and artists. Another very important transformation is creating a unique identifier column as we don't want to have to insert the same song played at the same time. A new column was created that combines the `song_id` with the time that the track was played in UNIX timestamp version (`UNIX_Time_Stamp`). You cannot play more than one song at a time on Spotify so it makes sense to implement this logic. To prepare the data for loading, we use two different data structures (Dictionary of Lists and List of Dictionaries), see more details in the [spotify_etl.py](https://github.com/PeterNdiforchu/Spotify-Music-Project/blob/a95db44916fd5e30a0d0bef19fb1f11aa241c4c1/spotify_project/spotify_etl.ipynb) jupyter notebook. The last step involves transforming the data structures into a dataframe, perform a series of datatime transformations, create unique identifiers for each song and prepare to load the data into a Postgres database.

# Load: Python and Postgres
I created a database on my computer using [Postgres](https://www.postgresql.org/). Postgres is an free open source relational database management system. You can follow these [steps](https://www.postgresqltutorial.com/postgresql-getting-started/install-postgresql/) to install postgres on your windows local machine and create the schema for the spotify database. Mac users can use these [steps](https://www.postgresqltutorial.com/postgresql-getting-started/install-postgresql-macos/) to install on mac. There are 3 main tables created using SQL Data Definition Language (DDL) for the Load(L) piece of the ETL process. You can find the SQL queries for creating the tables [here](https://github.com/PeterNdiforchu/Spotify-Music-Project/blob/a95db44916fd5e30a0d0bef19fb1f11aa241c4c1/spotify_project/Create_Tables.sql). To load the data in Postgres, we use the Pandas `.to_sql` method to load the data into a temporary table prior to inserting into the final database after making sure that the tracks are unique. Below is a picture of the ![database schema](https://github.com/PeterNdiforchu/Spotify-Music-Project/blob/a95db44916fd5e30a0d0bef19fb1f11aa241c4c1/spotify_project/spotify_schema.png).
